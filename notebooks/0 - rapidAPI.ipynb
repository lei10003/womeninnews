{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "from datetime import date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsrooms = pd.read_csv('../data/raw/newsrooms.csv')\n",
    "newsrooms.columns = ['site', 'monthly_visits', 'country', 'country_of_pub']\n",
    "newsrooms.dropna(inplace=True)\n",
    "newsrooms = newsrooms.drop_duplicates(subset = 'site')\n",
    "newsrooms = newsrooms.sort_values(by=['country_of_pub', 'monthly_visits'], ascending=False).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "UK = newsrooms[newsrooms['country_of_pub']=='UK'].reset_index().drop('index', axis=1)\n",
    "USA = newsrooms[newsrooms['country_of_pub']=='USA'].reset_index().drop('index', axis=1)\n",
    "India = newsrooms[newsrooms['country_of_pub']=='India'].reset_index().drop('index', axis=1)\n",
    "SA = newsrooms[newsrooms['country_of_pub']=='South Africa'].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites = list(SA.site.unique().flatten()) + list(USA.site.unique().flatten()) + list(UK.site.unique().flatten()) + list(India.site.unique().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(all_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "len(UK) + len(USA) + len(India) + len(SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "\n",
    "def get_three_month_ranges(year):\n",
    "    month_ranges = [[[1, 1, year], [31, 1, year]], \n",
    "                    [[1, 2, year], [28, 2, year]],\n",
    "                    [[1, 3, year], [31, 3, year]],\n",
    "                    [[1, 4, year], [30, 4, year]],\n",
    "                    [[1, 5, year], [31, 5, year]],\n",
    "                    [[1, 6, year], [30, 6, year]],\n",
    "                    [[1, 7, year], [31, 7, year]],\n",
    "                    [[1, 8, year], [31, 8, year]],\n",
    "                    [[1, 9, year], [30, 9, year]],\n",
    "                    [[1, 10, year], [31, 10, year]],\n",
    "                    [[1, 11, year], [30, 11, year]],\n",
    "                    [[1, 12, year], [31, 12, year]]]\n",
    "\n",
    "    two_month_ranges = []\n",
    "    for i in range(len(month_ranges)-1):\n",
    "        if i%2==0:\n",
    "            two_month_ranges.append((month_ranges[i][0], month_ranges[i+1][1]))\n",
    "\n",
    "    three_month_ranges = []\n",
    "    for i in range(len(month_ranges)-1):\n",
    "        if i%3==0:\n",
    "            three_month_ranges.append((month_ranges[i][0], month_ranges[i+2][1]))\n",
    "\n",
    "    return three_month_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_ranges = []\n",
    "for i in range(2010,2022):\n",
    "    month_ranges = month_ranges + get_three_month_ranges(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[([1, 4, 2021], [30, 6, 2021])]"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "month_ranges[45:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[193]"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "[all_sites.index('vogue.in')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['vogue.in',\n",
       " 'outlookindia.com',\n",
       " 'mensxp.com',\n",
       " 'deccanchronicle.com',\n",
       " 'sumanasa.com',\n",
       " 'swarajyamag.com',\n",
       " 'greaterkashmir.com',\n",
       " 'thebetterindia.com',\n",
       " 'freepressjournal.in',\n",
       " 'economictimes.indiatimes.com']"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "all_sites[193:203]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "len(month_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "([1, 1, 2010], [31, 3, 2010])\n1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in month_ranges[0:1]:\n",
    "    print(i)\n",
    "    from_date = f'{i[0][2]}-{i[0][1]}-{i[0][0]}'\n",
    "    to_date = f'{i[1][2]}-{i[1][1]}-{i[1][0]}'\n",
    "    year = i[0][2]\n",
    "    #bimester = i[1][1]/2\n",
    "    quarter = i[1][1]/3\n",
    "    print(quarter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Scraping outlookindia.com starting from 2021-4-1 to 2021-6-30\n",
      "Saved data from 100 articles of outlookindia.com to .csv!\n",
      "1 requests fired\n",
      "Scraping mensxp.com starting from 2021-4-1 to 2021-6-30\n",
      "Saved data from 100 articles of mensxp.com to .csv!\n",
      "2 requests fired\n",
      "Scraping deccanchronicle.com starting from 2021-4-1 to 2021-6-30\n",
      "Saved data from 100 articles of deccanchronicle.com to .csv!\n",
      "3 requests fired\n",
      "Scraping sumanasa.com starting from 2021-4-1 to 2021-6-30\n",
      "No data from sumanasa.com during this timeframe!\n",
      "4 requests fired\n",
      "Scraping swarajyamag.com starting from 2021-4-1 to 2021-6-30\n",
      "Saved data from 100 articles of swarajyamag.com to .csv!\n",
      "5 requests fired\n",
      "Scraping greaterkashmir.com starting from 2021-4-1 to 2021-6-30\n",
      "Saved data from 100 articles of greaterkashmir.com to .csv!\n",
      "6 requests fired\n",
      "Scraping thebetterindia.com starting from 2021-4-1 to 2021-6-30\n",
      "Saved data from 100 articles of thebetterindia.com to .csv!\n",
      "7 requests fired\n",
      "Scraping freepressjournal.in starting from 2021-4-1 to 2021-6-30\n",
      "Saved data from 100 articles of freepressjournal.in to .csv!\n",
      "8 requests fired\n",
      "Scraping economictimes.indiatimes.com starting from 2021-4-1 to 2021-6-30\n",
      "100%|██████████| 1/1 [00:20<00:00, 20.03s/it]Saved data from 100 articles of economictimes.indiatimes.com to .csv!\n",
      "9 requests fired\n",
      "Wall time: 20 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm\n",
    "headlines_dict = {}\n",
    "\n",
    "sites = all_sites[194:203]\n",
    "# sites = list(USA['site'].unique().flatten())[1:]\n",
    "\n",
    "url = \"https://google-news.p.rapidapi.com/v1/source_search\"\n",
    "# url = \"https://google-news1.p.rapidapi.com/search\"\n",
    "\n",
    "request_count = 0\n",
    "for i in tqdm(month_ranges[45:46]):\n",
    "    from_date = f'{i[0][2]}-{i[0][1]}-{i[0][0]}'\n",
    "    to_date = f'{i[1][2]}-{i[1][1]}-{i[1][0]}'\n",
    "    year = i[0][2]\n",
    "    #bimester = i[1][1]/2\n",
    "    quarter = i[1][1]/3\n",
    "\n",
    "    for site in sites:\n",
    "\n",
    "        print(\"Scraping\" ,site, \"starting from\", from_date, \"to\", to_date)\n",
    "\n",
    "        urls = []\n",
    "        headlines = []\n",
    "        times = []\n",
    "        scrape_dates = []\n",
    "        websites = []\n",
    "\n",
    "        # baseline news\n",
    "\n",
    "        querystring = { \"lang\":\"en\",\"from\":from_date,\"to\":to_date,\"source\":site}\n",
    "\n",
    "        # women's news\n",
    "\n",
    "        # querystring = {\"q\": \"women OR woman OR girl OR female OR lady OR ladies OR she OR her OR herself OR aunt OR grandmother OR mother OR sister\", \n",
    "                      # \"lang\":\"en\",\"from\":from_date,\"to\":to_date,\"source\":site}\n",
    "\n",
    "        headers = {\n",
    "\n",
    "            # Free API\n",
    "            'x-rapidapi-key': \"bd5010b7eemsh00ab5684fa6a7efp15b791jsnd00e2d098829\",\n",
    "            'x-rapidapi-host': \"google-news.p.rapidapi.com\"\n",
    "            }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "\n",
    "        request_count += 1\n",
    "\n",
    "        for j in range(len(response['articles'])):\n",
    "            headlines.append(response['articles'][j]['title'])\n",
    "            times.append(response['articles'][j]['published'])\n",
    "            urls.append(response['articles'][j]['link'])\n",
    "            websites.append(response['articles'][j]['source']['href'])\n",
    "\n",
    "        headlines_dict = {\"url\": urls, \"headline\": headlines, \"time\": times, \"scrape_date\": date.today().strftime(\"%d/%m/%Y\"), \"site\": site}\n",
    "\n",
    "        headlines_df = pd.DataFrame.from_dict(headlines_dict)\n",
    "        number_of_articles = len(headlines_df)\n",
    "        # save results to csv\n",
    "        if number_of_articles!=0:\n",
    "            \n",
    "            headlines_df.to_csv(f'../data/raw_baseline/{number_of_articles}_{site}_{quarter}_{year}_articles.csv')\n",
    "        # print final statement\n",
    "            print(\"Saved data from \" + str(number_of_articles) + \" articles of \"  + str(site) + \" to .csv!\")\n",
    "        else:\n",
    "            print(\"No data from \" + str(site) + \" during this timeframe!\")\n",
    "            \n",
    "        print(request_count, \"requests fired\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2005-2-28'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://google-news.p.rapidapi.com/v1/source_search\"\n",
    "\n",
    "querystring = {\"q\": \"women OR woman OR girl OR female OR lady OR ladies OR she OR her OR herself OR wife OR mom OR mother OR sister\", \n",
    "                       \"lang\":\"en\",\"from\":\"2005-1-1\",\"to\":\"2005-2-28\",\"source\":\"economictimes.indiatimes.com\"}\n",
    "\n",
    "# \"women OR woman OR girl OR female OR lady OR ladies OR she OR her OR herself OR aunt OR grandmother OR mother OR sister OR daughter OR wife OR mom OR mum OR girlfriend OR mrs OR niece\"        \n",
    "headers = {\n",
    "    'x-rapidapi-key': \"bd5010b7eemsh00ab5684fa6a7efp15b791jsnd00e2d098829\",\n",
    "    'x-rapidapi-host': \"google-news.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "\n",
    "# print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0c377a3a05ba1d31fd00218651f72b0a27b3c45e2b83cef10397a5da0ee866dc9",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}