{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "from datetime import date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsrooms = pd.read_csv('../data/raw/newsrooms.csv')\n",
    "newsrooms.columns = ['site', 'monthly_visits', 'country', 'country_of_pub']\n",
    "newsrooms.dropna(inplace=True)\n",
    "newsrooms = newsrooms.drop_duplicates(subset = 'site')\n",
    "newsrooms = newsrooms.sort_values(by=['country_of_pub', 'monthly_visits'], ascending=False).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "UK = newsrooms[newsrooms['country_of_pub']=='UK'].reset_index().drop('index', axis=1)\n",
    "USA = newsrooms[newsrooms['country_of_pub']=='USA'].reset_index().drop('index', axis=1)\n",
    "India = newsrooms[newsrooms['country_of_pub']=='India'].reset_index().drop('index', axis=1)\n",
    "SA = newsrooms[newsrooms['country_of_pub']=='South Africa'].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites = list(SA.site.unique().flatten()) + list(USA.site.unique().flatten()) + list(UK.site.unique().flatten()) + list(India.site.unique().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(UK) + len(USA) + len(India) + len(SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "\n",
    "def get_two_month_ranges(year):\n",
    "    month_ranges = [[[1, 1, year], [31, 1, year]], \n",
    "                    [[1, 2, year], [28, 2, year]],\n",
    "                    [[1, 3, year], [31, 3, year]],\n",
    "                    [[1, 4, year], [30, 4, year]],\n",
    "                    [[1, 5, year], [31, 5, year]],\n",
    "                    [[1, 6, year], [30, 6, year]],\n",
    "                    [[1, 7, year], [31, 7, year]],\n",
    "                    [[1, 8, year], [31, 8, year]],\n",
    "                    [[1, 9, year], [30, 9, year]],\n",
    "                    [[1, 10, year], [31, 10, year]],\n",
    "                    [[1, 11, year], [30, 11, year]],\n",
    "                    [[1, 12, year], [31, 12, year]]]\n",
    "\n",
    "    two_month_ranges = []\n",
    "    for i in range(len(month_ranges)-1):\n",
    "        if i%2==0:\n",
    "            two_month_ranges.append((month_ranges[i][0], month_ranges[i+1][1]))\n",
    "\n",
    "    return two_month_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_ranges = []\n",
    "for i in range(2005,2019):\n",
    "    month_ranges = month_ranges + get_two_month_ranges(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm\n",
    "headlines_dict = {}\n",
    "\n",
    "sites = all_sites\n",
    "# sites = list(USA['site'].unique().flatten())[1:]\n",
    "\n",
    "url = \"https://google-news.p.rapidapi.com/v1/source_search\"\n",
    "# url = \"https://google-news1.p.rapidapi.com/search\"\n",
    "\n",
    "request_count = 0\n",
    "for i in tqdm(month_ranges):\n",
    "    from_date = f'{i[0][2]}-{i[0][1]}-{i[0][0]}'\n",
    "    to_date = f'{i[1][2]}-{i[1][1]}-{i[1][0]}'\n",
    "    year = i[0][2]\n",
    "    bimester = i[1][1]/2\n",
    "\n",
    "    for site in sites:\n",
    "\n",
    "        print(\"Scraping\" ,site, \"starting from\", from_date, \"to\", to_date)\n",
    "\n",
    "        urls = []\n",
    "        headlines = []\n",
    "        times = []\n",
    "        scrape_dates = []\n",
    "        websites = []\n",
    "\n",
    "        # baseline news\n",
    "\n",
    "        #querystring = { \"lang\":\"en\",\"from\":from_date,\"to\":to_date,\"source\":site}\n",
    "\n",
    "        # women's news\n",
    "\n",
    "        querystring = {\"q\": \"women OR woman OR girl OR female OR lady OR ladies OR she OR her OR herself OR aunt OR grandmother OR mother OR sister OR daughter\", \n",
    "                       \"lang\":\"en\",\"from\":from_date,\"to\":to_date,\"source\":site}\n",
    "\n",
    "        headers = {\n",
    "            # Paid API\n",
    "            'x-rapidapi-key': \"bd5010b7eemsh00ab5684fa6a7efp15b791jsnd00e2d098829\",\n",
    "            # Free API\n",
    "            #'x-rapidapi-key': \"3e81132ebdmshafd93b150db164ep13c18fjsn834550268d59\",\n",
    "            'x-rapidapi-host': \"google-news.p.rapidapi.com\"\n",
    "            }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "\n",
    "        request_count += 1\n",
    "\n",
    "        for j in range(len(response['articles'])):\n",
    "            headlines.append(response['articles'][j]['title'])\n",
    "            times.append(response['articles'][j]['published'])\n",
    "            urls.append(response['articles'][j]['link'])\n",
    "            websites.append(response['articles'][j]['source']['href'])\n",
    "\n",
    "        headlines_dict = {\"url\": urls, \"headline\": headlines, \"time\": times, \"scrape_date\": date.today().strftime(\"%d/%m/%Y\"), \"site\": site}\n",
    "\n",
    "        headlines_df = pd.DataFrame.from_dict(headlines_dict)\n",
    "        number_of_articles = len(headlines_df)\n",
    "        # save results to csv\n",
    "        if number_of_articles!=0:\n",
    "            \n",
    "            headlines_df.to_csv(f'../data/raw_temporal/{number_of_articles}_{site}_{bimester}_{year}_articles.csv')\n",
    "        # print final statement\n",
    "            print(\"Saved data from \" + str(number_of_articles) + \" articles of \"  + str(site) + \" to .csv!\")\n",
    "        else:\n",
    "            print(\"No data from \" + str(site) + \" during this timeframe!\")\n",
    "            \n",
    "        print(request_count, \"requests fired\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2005-2-28'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://google-news.p.rapidapi.com/v1/source_search\"\n",
    "\n",
    "querystring = {\"q\": \"women OR woman OR girl OR female OR lady OR ladies OR she OR her OR herself OR wife OR mom OR mother OR sister\", \n",
    "                       \"lang\":\"en\",\"from\":\"2005-1-1\",\"to\":\"2005-2-28\",\"source\":\"economictimes.indiatimes.com\"}\n",
    "\n",
    "# \"women OR woman OR girl OR female OR lady OR ladies OR she OR her OR herself OR aunt OR grandmother OR mother OR sister OR daughter OR wife OR mom OR mum OR girlfriend OR mrs OR niece\"        \n",
    "headers = {\n",
    "    'x-rapidapi-key': \"bd5010b7eemsh00ab5684fa6a7efp15b791jsnd00e2d098829\",\n",
    "    'x-rapidapi-host': \"google-news.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feed': {'title': '\"allinurl:economictimes.indiatimes.com women OR woman OR girl OR female OR lady OR ladies OR she OR her OR herself OR wife OR mom OR mother OR sister after:2005-01-01 before:2005-02-28\" - Google News',\n",
       "  'updated': 'Fri, 14 May 2021 21:19:29 GMT',\n",
       "  'link': 'https://news.google.com/search?q=allinurl:economictimes.indiatimes.com+women+OR+woman+OR+girl+OR+female+OR+lady+OR+ladies+OR+she+OR+her+OR+herself+OR+wife+OR+mom+OR+mother+OR+sister+after:2005-01-01+before:2005-02-28&ceid=US:en&hl=en-US&gl=US',\n",
       "  'language': 'en-US',\n",
       "  'subtitle': 'Google News',\n",
       "  'rights': '2021 Google Inc.'},\n",
       " 'articles': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
